{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[수업자료](https://datascienceschool.net/03%20machine%20learning/01.01%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%98%20%EC%86%8C%EA%B0%9C.html)\n",
    "\n",
    "### 데이터 분석이란¶\n",
    "데이터 분석이란 어떤 데이터가 주어졌을 때, 데이터 간의 관계를 파악하거나 파악된 관계를 사용하여 우리가 원하는 새로운 (출력) 데이터를 만들어 내는 과정으로 볼 수 있다.\n",
    "\n",
    "### 예측¶\n",
    "**예측(prediction)**은 데이터 분석 작업 중 가장 많이 사용되는 유형 중 하나이다. 예측이란 숫자, 문서, 이미지, 음성, 영상 등의 여러 가지 입력 데이터를 주면, 데이터 분석의 결과로 다른 데이터를 출력하는 분석 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 규칙기반 방법과 학습기반 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 예측 문제를 풀려면 어떤 방법을 써야 할까? 예측을 하기 위한 방법론으로는 규칙기반(rule-based) 방법과 학습기반(traing-based) 또는 데이터기반(data-based) 방법이라는 두 가지 방법이 사용된다.\n",
    "\n",
    "규칙기반 방법은 어떤 입력이 들어오면 어떤 출력이 나오는지를 결정하는 **규칙이나 알고리즘**을 사람이 미리 만들어 놓는 방법이다(예를 들어, 규칙을 사람이 생각해 내는 것:지식이 많은 사람, epxert).\n",
    "\n",
    "규칙기반 방법의 가장 큰 문제는, 모든 케이스를 다 커버하는 룰을 만들기가 어려움. 사람이 병목.  \n",
    "\n",
    "규칙기반으로 처음 시도했던 것은 번역. 규칙을 정해서 번역을 시키려고 했던 것. 전문가들이 rule book을 만듬. 예를 들어, 'boy -> 소년', 'girl -> 소녀'로 해석해라. 이것이 바로 사전 혹은 문법. Rule Book을 이용해서 번역이라는 예측문제를 풀었던 것. \n",
    "\n",
    "이 규칙을 만드는 일 자체를 기계한테 시키자고 하는 것이 학습기반 방법. 이 학습을 기계가 하는 것. 학습의 목표는 규칙을 찾아내는 것. 학습을 하려면 데이터가 있어야 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습방법\n",
    "지도학습 : 이미지를 주고, 그게 개/고양이 인지 답을 미리 알려줘. 하나하나 정답을 일단 알려줘야 함. case by case에 대해 답을 다 알려줌. 사전을 주는 것이 아니라, 이때 어떻게 해석하는지 다 보여주는 것. \n",
    "\n",
    "\n",
    "각각의 사진에 “개” 혹은 “고양이”라는 출력 데이터(목표)값을 붙이는 작업은 당연히 사람이 수동으로 해야 한다. 그래서 이러한 방법을 지도학습(supervised learning) 방법이라고 한다.\n",
    "\n",
    "비유를 들자면 학습용 데이터 집합이란 정답이 표시된 수백 개의 문제를 모아놓은 문제집과 같고, 지도학습이란 이 문제집을 컴퓨터에 주고 학습시키는 것과 같다. 컴퓨터는 이 수백 개의 문제를 나름의 풀이방법으로 스스로 풀어본 다음, 정답을 이용하여 얼마나 맞았는지를 채점한다. 그런 다음 풀이방법을 스스로 조금씩 바꾸어 보면서 풀이와 채점을 반복한다. 이 과정을 반복하는 것이 지도학습이다. 따라서 지도학습이 얼마나 잘 되는가는 학습용 데이터의 양과 질에 크게 의존한다.\n",
    "\n",
    "학습용 데이터 집합에 붙어있는 출력 데이터, 즉 정답을 **목푯값(target)**이라고 한다. 지도학습의 목표는 주어진 목푯값과 최대한 비슷한 값을 출력하는 예측 방법을 찾아내는 것이다. 만약 입력데이터만 있고 이에 대응하는 목푯값이 없다면 각 입력데이터에 대해 사람이 원하는 목표값을 붙어 주어야 한다. 이러한 작업을 **레이블링(labelling, 문제 하나마다 정답을 만들어 놓는 것)**이라고 한다. 데이터의 양이 많고 복잡한 시스템을 만드는 경우에는 목푯값을 만드는 일, 즉 학습데이터를 만드는 일이 현실적으로 상당히 어려운 일이 될 수도 있다. \n",
    "\n",
    "레이블링이 지도학습에서 가장 힘든 작업. 답이 달린 문제집을 만들어 주는 과정이 보통 가장 힘든 작업임. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***이미지넷***\n",
    "\n",
    "이미지넷(ImageNet)은 페이페이 리(Fei-Fei Li) 교수가 이끄는 인공지능 팀이 만들어 2009년에 공개한 학습용 데이터셋이다. 320만장 이상의 이미지를 5,247개의 카테고리로 분류하였다. 이 작업은 아마존 미케니컬 터크(Amazon Mechanical Turk, 단순 노가다 작업 전 세계에 아웃소싱하는 서비스)라는 서비스를 통해 레이블링하였는데 이 서비스는 인터넷을 통해 전 세계에의 원하는 사람에게 간단한 작업을 지시하고 보수를 주는 시스템이다. 즉 인터넷을 통해 전 세계의 저비용 노동력을 사용하긴 했지만 결국 사람이 하나하나 이미지를 보면서 올바른 카테고리를 붙이는 작업을 한 것이다.\n",
    "\n",
    "이미지넷 시스템을 공개한 후 이를 기반으로 ILSVRC(ImageNet Large Scale Visual Recognition Challenge)라는 이미지 인식 경연대회가 열렸다. 2010년에 열린 첫번째 대회의 목표는 1000개의 카테고리를 가지는 120만장의 이미지를 학습데이터로 사용하고 20만장의 테스트 데이터를 이용하여 학습성능을 확인하는 것이었다. 이 대회를 통해 AlexNet 등의 딥러닝(인공신경망) 시스템의 우수성이 알려지기 시작하여 새로운 머신러닝의 시대가 열리게 되었다.\n",
    "\n",
    "보다 자세한 내용은 온라인 미디어 쿼츠(Quartz)의 기사를 참조하라( https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/ )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 예측 문제를 어떻게 출것이냐, 첫번째 단계가 바로 ***전처리와 인코딩***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리와 인코딩\n",
    "\n",
    "앞에서 숫자, 문서, 이미지, 음성, 영상 등의 여러 가지 데이터를 처리하는 것을 예시로 들었지만, 안타깝게도 현재 기술상 컴퓨터가 직접 처리할 수 있는 데이터는 사실 숫자(number)밖에 없다. 그렇다면 문서나 이미지와 같은 데이터는 어떻게 처리하는 것일까? 데이터 분석에서는 전처리(preprocessing) 또는 **인코딩(encoding)**이라는 과정을 통해 문서나 이미지와 같은 현실의 데이터를 컴퓨터가 처리할 수 있는 숫자 데이터로 바꾸어야 한다. 따라서 실제 예측 모형은 사실 다음과 같은 형태가 된다. 숫자가 아닌 데이터를 숫자로 바꾸는 과정이 필요하다는 것.알짜배기 숫자 정보로의 변환\n",
    "\n",
    "![1_2](./materials/1_1.png)\n",
    "![1_2](./materials/1_2.png)\n",
    "\n",
    "전처리는 단순히 비정형 데이터를 숫자로 바꾸는 것만 의미하는 것이 아니다. 전체 입력 정보 중 실제로 출력 데이터의 결정에 영향을 미칠만한 핵심 정보를 선택하거나 복수의 입력 데이터를 조합하여 새로운 입력 데이터를 만드는 것도 전처리의 중요한 역할이다. 전처리 과정은 최종 예측 성능에 커다란 영향을 끼친다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력차원\n",
    "\n",
    "앞에서 다룬 모형에서 중요한 점은 입력의 개수 즉, 숫자 벡터의 크기이다. 이를 **입력 차원(input dimension)**이라고 부르는데 일반적으로 입력 차원은 일단 정해지면 바꿀 수 없고 고정되어야 한다. 기본적으로 바꿀 수 없다고 봐야함. \n",
    "\n",
    "즉, 앞의 예제와 같이 64개의 숫자 입력을 가지는 경우, 다시 말해서 입력 차원이 64인 예측 시스템을 만들었다면 이 모형에는 128개의 숫자 입력은 적용할 수 없다. 따라서 해상도가 128차원인 이미지를 입력 데이터로 써서 예측하려면 여기에 맞는 128차원 입력 예측 모형을 처음부터 새로 만들든지, 아니면 128차원 데이터를 어떤 방법으로든 64차원으로 줄이는 방법밖에 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 데이터는 어떻게 하지? 길이가 다 제각각이야. 그런데 예측 시스템을 한번 만들면 입력차원은 기본적으로 바뀔 수가 없음. 어떻게 해결하지?\n",
    "\n",
    "### 인코딩의 다른 예 : 문서 데이터\n",
    "\n",
    "그럼 문서 데이터는 어떻게 인코딩하여 숫자로 변환할까? 문서 데이터를 숫자로 변환할 때 가장 어려운 점은 영상과 달리 크기가 제각각이라는 점이다. 즉, 5개 단어로 이루어진 한 문장으로 된 문서도 있고, 수천 개의 단어로 이루어진 장문의 문서도 있는데 이것을 같은 크기의 숫자로 바꾸어야 한다.\n",
    "\n",
    "이러한 문서 데이터를 고정된 크기의 숫자 벡터로 바꾸는 방법 중 가장 널리 쓰이는 것은 **’BOW(Bag of Words)’**라는 방법이다. 이 방법은 문서를 이루는 단어의 순서, 의미 등의 정보를 모두 무시하고 오로지 특정한 단어가 문서에 몇 번 나왔는지만 세어 그 빈도를 벡터로 표시하는 방법이다.\n",
    "\n",
    "예를 들어 대부분의 문서가 10,000개의 단어 중 일부로 구성되어 있다면, 각 단어에 1부터 10,000이라는 번호를 붙인다. 이를 단어장(vovaulary)이라고 한다. 그리고 어떤 하나의 문서를 하나의 숫자 벡터로 바꾸려면 해당 문서에 1번 단어가 한 번 나오면 숫자 벡터의 첫번째 원소값이 1이 되고, 2번 단어가 한 번도 나오지 않는다면 숫자 벡터의 두 번째 원소값이 0이 된다. 이러한 방식으로 어떤 길이를 가지는 문서든 ***10,000개***의 길이를 가지는 숫자 벡터로 바꿀 수 있다.\n",
    "\n",
    "다음 예제는 “20 newsgroups” 라고 불리는 문서 표본 데이터의 하나이다. 여기에서 첫번째 데이터(문서)는 다음과 같다.\n",
    "\n",
    "\n",
    "`아래 표에서 가로 한칸마다 단어 종류를 표현하고, 세로 한칸마다 다른 문서를 의미.\n",
    "점이 찍혀 있는 것은 해당 문서에는 해당 단어가 들어가 있다는 것. 찐할수록 많이 들어가 있다는 뜻이겠지. \n",
    "하얀 부분은 그 단어 없다는 것`\n",
    "![1_2](./materials/1_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카테고리값\n",
    "\n",
    "앞에서 컴퓨터가 다룰 수 있는 데이터는 숫자 데이터 뿐이라고 했는데 사실은 한가지 종류의 데이터를 더 다룰 수 있다. 바로 카테고리(category)값 또는 범주형 값이라고 부르는 데이터이다.\n",
    "\n",
    "카테고리값은 숫자 값과 달리 주로 기호로 표시되며 비연속적이다. 하지만 더 중요한 차이점은 두 개의 데이터가 있을 때 이들의 크기나 가치, 혹은 순서를 비교할 수 있는가 없는가이다. 예를 들어 10kg과 20kg이라는 두 개의 무게는 20이 10보다 “두 배정도 크다”라고 크기를 비교하는 것이 가능하다. 그러나 “고양이”와 “개”라는 두 개의 카테고리값은 크기나 가치를 비교할 수 없다.\n",
    "\n",
    "일반적으로 카테고리값은 가질 수 있는 경우의 수가 제한되어 있다. 이러한 경우의 수를 ‘***클래스(class)***’라고 부르는데 동전을 던진 결과와 같이 “앞면(head)” 혹은 “뒷면(tail)”처럼 두 가지 경우만 가능하면 ‘***이진 클래스(binary class)***’라고 한다. 그리고 주사위를 던져서 나온 숫자와 같이 세 개 이상의 경우가 가능하면 ‘***다중 클래스(multi class)***’라고 한다.\n",
    "\n",
    "카테고리값처럼 비연속적이지만 숫자처럼 비교 가능한 경우도 있을 수 있다. 예를 들어 학점을 “A”, “B”, “C”, “D”와 같이 주는 경우는 비연속적이고 기호로 표시되지만, 크기 혹은 순서를 비교할 수 있다. 이러한 경우는 분석의 목표에 따라 숫자로 표기하기도 하고 일반적인 카테고리값으로 표기하기도 한다.\n",
    "\n",
    "원래 카테고리 자체는 서로 비교할 수가 없는게 맞긴 함. 그러나, 크기 비교 가능한 카테고리도 있음. 학점 등. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀분석과 분류\n",
    "\n",
    "***예측 문제는 출력하고자 하는 데이터가 숫자 값인가 카테고리값인가에 따라 사용하는 방법이 완전히 달라진다.***\n",
    "\n",
    "출력하고자 하는 값이 숫자인 경우를 **회귀분석(regression analysis)**이라고 하며, 전통적인 통계분석에서 많이 사용하는 예측 방법이다. 반대로 출력하고자 하는 값이 카테고리값인 경우는 **분류(classification)**라고 부른다. 머신러닝 방법은 대부분 이러한 분류 문제를 풀기위한 방법이다.\n",
    "\n",
    "분류 문제는 우리가 푸는 시험문제 중 4지 선다형 객관식 문제와 같은 것으로 생각할 수 있다. 반대로 회귀 분석은 답이 되는 숫자를 직접 써야 하는 단답형 문제라고 할 수 있다.\n",
    "\n",
    "예를 들어 이미지를 컴퓨터에 입력했을 때 “개”인지 “고양이”인지 판별하는 문제는 사실 내부적으로 분류 문제를 사용한다. 보통 1,000개 혹은 그 이상의 가능한 이미지 카테고리 목록을 준비하고 해당 이미지가 이 카테고리에서 어떤 것에 해당하는지를 찾아내는 1,000지 선다형 객관식 문제와 같은 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 숫자를 예측 : 회귀분석\n",
    "- 카테고리를 예측 : 분류문제 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류하는 방식은 알고리즘에 따라 다양한 방법이 있음. 다만, 아래는 SVM이라는 방법을 써서 분류 한 것(직선으로 분류하는 방법 중 하나).\n",
    "- 초록색과 파란색의 경계 부분 보면, 잘못 분류된 곳들이 있을 수 있지. \n",
    "- 그러면 곡선으로? 근데 곡선으로 하면 잘하는 것일까? 이게 가장 어려운 문제. \n",
    "- 우리의 목표는 예측을 하는 것. 그런데 여기있는 데이터는 샘플용. 샘플에 과다하게 맞추게 되면, 실제 데이터가 잘 맞을까? 그게 관건. \n",
    "- 결국은 다른 데이터를 가지고 비교를 해봐야 함. 진짜 현상을 알아봐야 함. cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_2](./materials/1_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비지도학습\n",
    "\n",
    "지금까지 말한 지도학습방법 이외의 모든 나머지 방법을 비지도학습이라고 부른다. \n",
    "\n",
    "지금까지 살펴본 지도학습에서는 입력값과 출력값의 쌍(pair)을 학습데이터로 하여 입력값에 대한 출력값을 예측하도록 학습을 시켰다. 하지만 때로는 데이터간에 입력과 출력의 관계가 명확하지 않을 수도 있다. 이렇게 입력/출력이 구분되지 않는 단순한 “데이터들의 관계”에서 특정한 규칙을 찾아내는 것을 **비지도학습(unsupervised learning)**이라고 한다. 비지도학습에서는 입력/출력 데이터를 구분짓지 않고 단순히 데이터를 입력하면 이 데이터들간의 규칙을 찾아내거나 미리 지정한 규칙(모형)에 맞는 데이터인지를 구분해 낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터링\n",
    "\n",
    "데이터가 비슷한놈끼리 묶는 방식(데이터들간의 관계를 찾아내는 것이 비지도학습)\n",
    "\n",
    "X만 넣고 정답은 주어지지 않는다. 비슷한 애들끼리 묵는다. \n",
    "\n",
    "대표적인 비지도학습 방법 중 하나는 데이터들을 유사한 데이터까지 같은 그룹으로 모으는 클러스터링(clustering) 방법이다. 다음 예제는 100개의 2차원 데이터들을 affinity propagation이라는 방법으로 클러스터링한 결과이다. 왼쪽 그림은 클러스터링을 하기 전의 데이터들을 나타낸 것이고 오른쪽 그림은 클러스터링으로 모아진 데이터를 나타낸 것이다. 전체 데이터를 3개의 그룹으로 분리할 수 있다는 것을 알 수 있다.\n",
    "\n",
    "\n",
    "아래 방식은 클러스터링 중에서도 Affinity Propagation 방식\n",
    "\n",
    "![Clustering](./materials/1_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클러스터링 이외에도, x1/x2/x3를 쌍으로 주면서 계속 학습 시키다가 나중에, x2/x3쌍만 주고 x1에 뭐 들어가니? 물어보는 이런 문제들도 있음(Imputation/Impainting). \n",
    "Unsupervised Learning은 범위가 엄청 광범위함. \n",
    "\n",
    "\n",
    "응용하면, 이미지데이터를 계속 보여주고 난 다음에, 나중에 이미지에 구멍 뚫고 알아맞히는 알고리즘 등(**Impainting**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용하게 될 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statsmodels 패키지\n",
    "\n",
    "R에 있는 거의 모든 것을 다 할수 있음(애초에 R을 본떠 만듬).\n",
    "다음 명령으로 설치한다.<br>\n",
    "```pip install statsmodels```\n",
    "임포트할 때는 보통 api 서브패키지를 sm이라는 별명으로 임포트한다.\n",
    "```import statsmodels.api as sm```\n",
    "\n",
    "\n",
    "\n",
    "statsmodels(“스탯츠모델즈”라고 읽는다) 패키지는 추정 및 검정, 회귀분석, 시계열분석 등의 기능을 제공하는 파이썬 패키지다. 기존에 R에서 가능했던 다양한 회귀분석과 시계열분석 방법론을 그대로 파이썬에서 이용할 수 있다. 다음은 statsmodels 패키지가 제공하는 기능의 일부다.\n",
    "\n",
    "<br>\n",
    "\n",
    "예제 데이터셋\n",
    "\n",
    "검정 및 모수추정\n",
    "\n",
    "회귀분석\n",
    "\n",
    "선형회귀\n",
    "\n",
    "강건회귀\n",
    "\n",
    "일반화 선형모형\n",
    "\n",
    "혼합효과모형\n",
    "\n",
    "이산종속변수\n",
    "\n",
    "시계열 분석\n",
    "\n",
    "SARIMAX 모형\n",
    "\n",
    "상태공간 모형\n",
    "\n",
    "벡터 AR 모형\n",
    "\n",
    "생존분석\n",
    "\n",
    "요인분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn 패키지\n",
    "\n",
    "\n",
    "설치와 임포트에 사용하는 이름은 sklearn이다.<br> \n",
    "다음 명령으로 설치한다.\n",
    "`pip install sklearn`\n",
    "임포트할 때는 보통 sk이라는 별명으로 임포트한다.\n",
    "`import sklearn as sk`\n",
    "\n",
    "\n",
    "scikit-learn(“사이킷런”이라고 읽는다) 패키지는 머신러닝 교육을 위한 최고의 파이썬 패키지다. scikit-learn 패키지의 장점은 다양한 머신러닝 모형을 하나의 패키지에서 모두 제공하고 있다는 점이다. 다음은 scikit-learn 패키지에서 제공하는 머신러닝 모형의 목록의 일부다.\n",
    "\n",
    "- 데이터셋\n",
    "    - 회귀분석, 분류, 클러스터링용 가상 데이터셋 생성\n",
    "    - 각종 벤치마크 데이터셋\n",
    "\n",
    "- 전처리\n",
    "\n",
    "    - 스케일링\n",
    "    - 누락데이터 처리\n",
    "    - 텍스트 토큰화\n",
    "\n",
    "- 지도학습\n",
    "\n",
    "    - 회귀분석\n",
    "    - LDA/QDA\n",
    "    - 서포트벡터머신\n",
    "    - 퍼셉트론, SGD\n",
    "    - KNN\n",
    "    - 가우스프로세스\n",
    "    - 나이브베이즈\n",
    "    - 의사결정나무\n",
    "    - 랜덤포레스트, 부스팅\n",
    "\n",
    "- 비지도학습\n",
    "    - 가우스 혼합모형\n",
    "    - 클러스터링\n",
    "    - PCA\n",
    "- 성능 최적화\n",
    "- 교차검증\n",
    "- 특징선택\n",
    "- 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 전처리용 패키지\n",
    "    - missingno 패키지\n",
    "    - pandas 데이터프레임 데이터에서 누락된 데이터를 찾고 시각화하는 기능을 제공한다.\n",
    "\n",
    "    - 다음 명령으로 설치한다.\n",
    "        `pip install missingno`\n",
    "\n",
    "- patsy 패키지¶\n",
    "    - pandas 데이터프레임 데이터에서 선택, 변형하는 기능을 제공한다.\n",
    "    - statsmodels가 의존하는 패키지이므로 statsmodels 패키지를 설치하면 별도로 설치할 필요가 없다.\n",
    "\n",
    "- 텍스트 전처리용 패키지¶\n",
    "    - nltk 패키지¶\n",
    "    - spacy 패키지¶\n",
    "    - konlpy 패키지(한글 할때)¶\n",
    "    - soynlp 패키지(한글 할때)\n",
    "    - gensim 패키지¶\n",
    "- 이미지 전처리용 패키지¶\n",
    "    - opencv 패키지¶\n",
    "- 사운드 전처리용 패키지¶\n",
    "    - librosa 패키지¶\n",
    "- 지리정보 전처리용 패키지¶\n",
    "    - geopandas 패키지¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

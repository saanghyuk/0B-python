{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모형최적화 \n",
    "2. 비대칭 데이터 문제\n",
    "3. 특징 선택 \n",
    "4. 대규모 데이터 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신 러닝 모형이 완성된 후에는 최적화 과정을 통해 예측 성능을 향상시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn 의 모형 하이퍼 파라미터 튜닝 도구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn에서는 다음과 같은 모형 최적화 도구를 지원한다.\n",
    "\n",
    "* [`validation_curve`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)\n",
    "  * 단일 하이퍼 파라미터 최적화\n",
    "* [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "  * 그리드를 사용한 복수 하이퍼 파라미터 최적화\n",
    "* [`ParameterGrid`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html)  \n",
    " * 복수 파라미터 최적화용 그리드\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `validation_curve` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`validation_curve` 함수는 최적화할 파라미터 이름과 범위, 그리고 성능 기준을 `param_name`, `param_range`, `scoring` 인수로 받아 파라미터 범위의 모든 경우에 대해 성능 기준을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "param_range = np.logspace(-6, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_scores, test_scores = \\\n",
    "    validation_curve(SVC(), X, y,\n",
    "                     param_name=\"gamma\", param_range=param_range,\n",
    "                     cv=10, scoring=\"accuracy\", n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "mpl.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "plt.semilogx(param_range, test_scores_mean,\n",
    "             label=\"Cross-validation score\", color=\"g\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV`  클래스는 `validation_curve` 함수와 달리 모형 래퍼(Wrapper) 성격의 클래스이다.  클래스 객체에 `fit` 메서드를 호출하면 grid search를 사용하여 자동으로 복수개의 내부 모형을 생성하고 이를 모두 실행시켜서 최적 파라미터를 찾아준다. 생성된 복수개와 내부 모형과 실행 결과는 다음 속성에 저장된다.\n",
    "\n",
    "* `grid_scores_ `\n",
    " * param_grid 의 모든 파리미터 조합에 대한 성능 결과. 각각의 원소는 다음 요소로 이루어진 튜플이다.\n",
    "  * parameters: 사용된 파라미터\n",
    "  * mean_validation_score: 교차 검증(cross-validation) 결과의 평균값\n",
    "  * cv_validation_scores: 모든 교차 검증(cross-validation) 결과\n",
    "* `best_score_` \n",
    " * 최고 점수 \n",
    "* `best_params_`\n",
    " * 최고 점수를 낸 파라미터\n",
    "* `best_estimator_`\n",
    " * 최고 점수를 낸 파라미터를 가진 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()), ('clf', SVC(random_state=1))])\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [\n",
    "    {'clf__C': param_range, 'clf__kernel': ['linear']},\n",
    "    {'clf__C': param_range, 'clf__gamma': param_range, 'clf__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid,\n",
    "                  scoring='accuracy', cv=10, n_jobs=1)\n",
    "%time gs = gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.cv_results_[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ParameterGrid`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "때로는 scikit-learn 이 제공하는 GridSearchCV 이외의 방법으로 그리드 탐색을 해야하는 경우도 있다. 이 경우 파라미터를 조합하여 탐색 그리드를 생성해 주는 명령어가 `ParameterGrid` 이다. `ParameterGrid` 는 탐색을 위한 iterator 역할을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'a': [1, 2], 'b': [True, False]}\n",
    "list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'kernel': ['linear']}, {'kernel': ['rbf'], 'gamma': [1, 10]}]\n",
    "list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 병렬 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` 명령에는 `n_jobs` 라는 인수가 있다. 디폴트 값은 1인데 이 값을 증가시키면 내부적으로 멀티 프로세스를 사용하여 그리드서치를 수행한다. 만약 CPU 코어의 수가 충분하다면 `n_jobs`를 늘릴 수록 속도가 증가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"gamma\": np.logspace(-6, -1, 10)}\n",
    "gs1 = GridSearchCV(estimator=SVC(), param_grid=param_grid,\n",
    "                   scoring='accuracy', cv=5, n_jobs=1)\n",
    "gs2 = GridSearchCV(estimator=SVC(), param_grid=param_grid,\n",
    "                   scoring='accuracy', cv=5, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs2.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 하드웨어의 코어 수가 부족하다면 병렬로 실행되지 않으므로 실행시간이 단축되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비대칭 데이터 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 클래스 비율이 너무 차이가 나면(highly-imbalanced data) 단순히 우세한 클래스를 택하는 모형의 정확도가 높아지므로 모형의 성능판별이 어려워진다. 즉, 정확도(accuracy)가 높아도 데이터 갯수가 적은 클래스의 재현율(recall-rate)이 급격히 작아지는 현상이 발생할 수 있다.\n",
    "\n",
    "이렇게 각 클래스에 속한 데이터의 갯수의 차이에 의해 발생하는 문제들을 비대칭 데이터 문제(imbalanced data problem)이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def classification_result(n0, n1, title=\"\"):\n",
    "    rv1 = sp.stats.multivariate_normal([-1, 0], [[1, 0], [0, 1]])\n",
    "    rv2 = sp.stats.multivariate_normal([+1, 0], [[1, 0], [0, 1]])\n",
    "    X0 = rv1.rvs(n0, random_state=0)\n",
    "    X1 = rv2.rvs(n1, random_state=0)\n",
    "    X = np.vstack([X0, X1])\n",
    "    y = np.hstack([np.zeros(n0), np.ones(n1)])\n",
    "\n",
    "    x1min = -4; x1max = 4\n",
    "    x2min = -2; x2max = 2\n",
    "    xx1 = np.linspace(x1min, x1max, 1000)\n",
    "    xx2 = np.linspace(x2min, x2max, 1000)\n",
    "    X1, X2 = np.meshgrid(xx1, xx2)\n",
    "\n",
    "    plt.contour(X1, X2, rv1.pdf(np.dstack([X1, X2])), levels=[0.05], linestyles=\"dashed\")\n",
    "    plt.contour(X1, X2, rv2.pdf(np.dstack([X1, X2])), levels=[0.05], linestyles=\"dashed\")\n",
    "\n",
    "    model = SVC(kernel=\"linear\", C=1e4, random_state=0).fit(X, y)\n",
    "    Y = np.reshape(model.predict(np.array([X1.ravel(), X2.ravel()]).T), X1.shape)\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], marker='x', label=\"0 클래스\")\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], marker='o', label=\"1 클래스\")\n",
    "    plt.contour(X1, X2, Y, colors='k', levels=[0.5])\n",
    "    y_pred = model.predict(X)\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-3, 3)\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    return model, X, y, y_pred\n",
    "    \n",
    "plt.subplot(121)\n",
    "model1, X1, y1, y_pred1 = classification_result(200, 200, \"대칭 데이터 (5:5)\")\n",
    "plt.subplot(122)\n",
    "model2, X2, y2, y_pred2 = classification_result(200, 20, \"비대칭 데이터 (9:1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y1, y_pred1))\n",
    "print(classification_report(y2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "\n",
    "fpr1, tpr1, thresholds1 = roc_curve(y1, model1.decision_function(X1))\n",
    "fpr2, tpr2, thresholds2 = roc_curve(y2, model2.decision_function(X2))\n",
    "\n",
    "c1 = confusion_matrix(y1, y_pred1, labels=[1, 0])\n",
    "c2 = confusion_matrix(y2, y_pred2, labels=[1, 0])\n",
    "r1 = c1[0, 0] / (c1[0, 0] + c1[0, 1])\n",
    "r2 = c2[0, 0] / (c2[0, 0] + c2[0, 1])\n",
    "f1 = c1[1, 0] / (c1[1, 0] + c1[1, 1])\n",
    "f2 = c2[1, 0] / (c2[1, 0] + c2[1, 1])\n",
    "\n",
    "plt.plot(fpr1, tpr1, ':', label=\"대칭\")\n",
    "plt.plot(fpr2, tpr2, '-', label=\"비대칭\")\n",
    "plt.plot([f1], [r1], 'ro')\n",
    "plt.plot([f2], [r2], 'ro')\n",
    "plt.legend()\n",
    "plt.xlabel('Fall-Out')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('ROC 커브')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해결 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비대칭 데이터는 다수 클래스 데이터에서 일부만 사용하는 **언더 샘플링**이나 소수 클래스 데이터를 증가시키는 **오버 샘플링**을 사용하여 데이터 비율을 맞추면 정밀도(precision)가 향상된다.\n",
    "\n",
    "* 오버샘플링(Over-Sampling)\n",
    "* 언더샘플링(Under-Sampling)\n",
    "* 복합샘플링(Combining Over-and Under-Sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imbalanced-learn 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imbalanced data 문제를 해결하기 위한 다양한 샘플링 방법을 구현한 파이썬 패키지\n",
    "\n",
    "\n",
    "```\n",
    "pip install -U imbalanced-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언더 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `RandomUnderSampler`: random under-sampling method\n",
    "* `TomekLinks`: Tomek’s link method\n",
    "* `CondensedNearestNeighbour`: condensed nearest neighbour method\n",
    "* `OneSidedSelection`: under-sampling based on one-sided selection method\n",
    "* `EditedNearestNeighbours`: edited nearest neighbour method\n",
    "* `NeighbourhoodCleaningRule`: neighbourhood cleaning rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import *\n",
    "\n",
    "n0 = 200; n1 = 20\n",
    "rv1 = sp.stats.multivariate_normal([-1, 0], [[1, 0], [0, 1]])\n",
    "rv2 = sp.stats.multivariate_normal([+1, 0], [[1, 0], [0, 1]])\n",
    "X0 = rv1.rvs(n0, random_state=0)\n",
    "X1 = rv2.rvs(n1, random_state=0)\n",
    "X_imb = np.vstack([X0, X1])\n",
    "y_imb = np.hstack([np.zeros(n0), np.ones(n1)])\n",
    "\n",
    "x1min = -4; x1max = 4\n",
    "x2min = -2; x2max = 2\n",
    "xx1 = np.linspace(x1min, x1max, 1000)\n",
    "xx2 = np.linspace(x2min, x2max, 1000)\n",
    "X1, X2 = np.meshgrid(xx1, xx2)\n",
    "\n",
    "def classification_result2(X, y, title=\"\"):\n",
    "    plt.contour(X1, X2, rv1.pdf(np.dstack([X1, X2])), levels=[0.05], linestyles=\"dashed\")\n",
    "    plt.contour(X1, X2, rv2.pdf(np.dstack([X1, X2])), levels=[0.05], linestyles=\"dashed\")\n",
    "    model = SVC(kernel=\"linear\", C=1e4, random_state=0).fit(X, y)\n",
    "    Y = np.reshape(model.predict(np.array([X1.ravel(), X2.ravel()]).T), X1.shape)\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], marker='x', label=\"0 클래스\")\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], marker='o', label=\"1 클래스\")\n",
    "    plt.contour(X1, X2, Y, colors='k', levels=[0.5])\n",
    "    y_pred = model.predict(X)\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-3, 3)\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.title(title)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ramdom Under-Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 무작위로 데이터를 없애는 단순 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = RandomUnderSampler(random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tomek’s link method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토멕링크(Tomek’s link)란 서로 다른 클래스에 속하는 한 쌍의 데이터 $(x_{+}, x_{-})$로 서로에게 더 가까운 다른 데이터가 존재하지 않는 것이다. 즉 클래스가 다른 두 데이터가 아주 가까이 붙어있으면 토멕링크가 된다. 토멕링크 방법은 이러한 토멕링크를 찾은 다음 그 중에서 다수 클래스에 속하는 데이터를 제외하는  방법으로 경계선을 다수 클래스쪽으로 밀어붙이는 효과가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<picture>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = TomekLinks(random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensed Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(Condensed Nearest Neighbour) 방법은 1-NN 모형으로 분류되지 않는 데이터만 남기는 방법이다. 선텍된 데이터 집합을 $S$라고 하자.\n",
    "\n",
    "1. 소수 클래스 데이터를 모두 $S$에 포함시킨다.\n",
    "2. 다수 데이터 중에서 하나를 골라서 가장 가까운 데이터가 다수 클래스이면 포함시키지 않고 아니면 $S$에 포함시킨다.\n",
    "3. 더이상 선택되는 데이터가 없을 때까지 2를 반복한다.\n",
    "\n",
    "이 방법을 사용하면 기존에 선택된 데이터와 가까이 있으면서 같은 클래스인 데이터는 선택되지 않기 때문에 다수 데이터의 경우 선택되는 비율이 적어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = CondensedNearestNeighbour(random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Sided Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Sided Selection은 토맥링크 방법과 Condensed Nearest Neighbour 방법을 섞은 것이다. 토맥링크 중 다수 클래스를 제외하고 나머지 데이터 중에서도 서로 붙어있는 다수 클래스 데이터는 1-NN 방법으로 제외한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = OneSidedSelection(random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENN(Edited Nearest Neighbours) 방법은 다수 클래스 데이터 중 가장 가까운 k(`n_neighbors`)개의 데이터가 모두(`kind_sel=\"all\"`) 또는 다수(`kind_sel=\"mode\"`) 다수 클래스가 아니면 삭제하는 방법이다. 소수 클래스 주변의 다수 클래스 데이터는 사라진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = EditedNearestNeighbours(kind_sel=\"all\", n_neighbors=5, random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbourhood Cleaning Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neighbourhood Cleaning Rule 방법은 CNN(Condensed Nearest Neighbour) 방법과 ENN(Edited Nearest Neighbours) 방법을 섞은 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = NeighbourhoodCleaningRule(kind_sel=\"all\", n_neighbors=5, random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오버 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `RandomOverSampler`: random sampler\n",
    "* `ADASYN`: Adaptive Synthetic Sampling Approach for Imbalanced Learning\n",
    "* `SMOTE`: Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Over Sampling은 소수 클래스의 데이터를 반복해서 넣는 것(replacement)이다. 가중치를 증가시키는 것과 비슷하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = RandomOverSampler(random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN(Adaptive Synthetic Sampling) 방법은 소수 클래스 데이터와 그 데이터에서 가장 가까운 k개의 소수 클래스 데이터 중 무작위로 선택된 데이터 사이의 직선상에 가상의 소수 클래스 데이터를 만드는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = ADASYN(random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE(Synthetic Minority Over-sampling Technique) 방법도 ADASYN 방법처럼 데이터를 생성하지만 생성된 데이터를 무조건 소수 클래스라고 하지 않고 분류 모형에 따라 분류한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<picture>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = SMOTE(random_state=4).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 복합 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `SMOTEENN`: SMOTE + ENN\n",
    "* `SMOTETomek`: SMOTE + Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE+ENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE+ENN 방법은 SMOTE(Synthetic Minority Over-sampling Technique) 방법과 ENN(Edited Nearest Neighbours) 방법을 섞은 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = SMOTEENN(random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE+Tomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE+Tomek 방법은 SMOTE(Synthetic Minority Over-sampling Technique) 방법과 토멕링크 방법을 섞은 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = SMOTETomek(random_state=4).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_imb, model_samp.predict(X_imb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

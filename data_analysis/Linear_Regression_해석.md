# Linear Regression 해석

![1_9](./materials/1_9.png)

| Name                                                         | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| Dep. Variable:  MEDV                                         | 종속변수                                                     |
| Model: OLS                                                   | OLS방법론으로 시행                                           |
| Method: Least Squares                                        | OLS중에서도 Least Square라는 방법을 썻다.                    |
| No. Observations:   506                                      | 데이터의 갯수                                                |
| Df Residuals:  492                                           | 쓴 변수의 갯수 + 상수항 더하면 14개. 그 14개를 데이터갯수에서 빼준 값이 ***잔차의 자유도*** |
| Df Model:  13                                                | 쓴 변수의 갯수                                               |
| P > \|t\|                                                    | P가 P검정의 유의확률을 의미함. p가 0에 가까우면, 귀무가설을 Reject한 것. 여기서의 귀무가설은, **"Coef값이 0이다"** 이게 귀무가설. 원래는 0인데, 노이즈가 끼다 보니간, 0이 아닌 값이 나온 것일 뿐이다 라는 것이 귀무가설. 예컨대 이 값이 0.491이라고 나와있으면, coef에 -0.5050이라고 써 있어도 아무 의미가 없다는 뜻. 사실 0이라는 뜻. |
| std err                                                      | 우리가 구한, w값에 대한 오차를 말하는 것. 표준오차. [0.25, 0.75]에 써있는 것은, 구한 w값에다가 +-2*standard error 한 값. 이게 신기한게, 우리가 전체 데이터를 가지고, 1000번을 리샘플링 해서(bootstraping) 일부만 추출해서 분포를 그린다음에 걔의 표준편차를 구하면, 얘랑 비슷하게 나옴. 얘는 **확률론적 선형회귀모형**을 사용한 것. <br> 우리가 예측한 w라는 것이, 오차가 +- 이정도 있을 수 있다는 것. w라는 확률변수의 표준편차를 추론한 것. <br>[0.975-0.025=0.95] 즉, 표에서 이 두 값을 주는 이유는, +-2 std_err 안에 있을 확률이 95%라는 것. **95% 신뢰구간** 이라고 부른다. 95%의 확률로 이 안에 분명히 있다는 뜻. |
| t                                                            | **coef / std_error**. 원래는, t분포 따르게 하려면, 우리가 구한 w hat에서 실제 w를 빼고 그 다음에 표준오차를 나눠줘야 하는데, 우리는 정답을 모르잖아. 그러니깐, w가 0 이라고 가정한 것. 실제로는 우리가 ***귀무가설을 실제 w=0이다.*** 이렇게 놓은 것. |
| F-statistics(이건 그냥 검정통계량), 우리가 보는 것은 Prob(F-statistics) | 이는 전체 독립 변수 중 어느 것도 의미를 가진 것이 없다는 뜻이다. 대부분의 경우, 이 귀무가설은 기각된다. 다만 유의 확률이 얼마나 작은가에 따라서 기각되는 정도가 달라진다. 유의 확률이 작으면 작을수록 더 강력하게 기각된 것이므로 더 의미가 있는 모형이라고 할 수 있다. 따라서 여러 모형의 유의 확률을 비교하여 어느 모형이 더 성능이 좋은가를 비교할 때 이 유의 확률을 사용한다. Loss of fit이라고 부른다. |
| Omnibus/Prob(Omnibus)                                        | **귀무가설 = "잔차의 분포는 정규분포이다."** 정규성 검정. 잔차가 정규분포인지 따진 것. 우리 모델에 따르면, 잔차는 정규분포여야 함. 정규분포가 아니면 뭐가 잘못된 것. P-value가 0이네 지금. 뭔가 잘못됬네. |
| Jarque-Bera/Prob(Jarque-Bera)                                | 이것도 귀무가설 Omnibus Test와 동일.                         |
| Cond. No.                                                    | 다중공선성이나 스케일링에 대한 체크                          |
| Skew/Kurtosis                                                | 정규분포 따지면서, 혹시라도 이런 값들을 보면서 판단할 수도 있으니깐, 넣어놓은 것. 잔차분포의 skew/kurtosis를 나타낸 것. |
| Durbin-Watson                                                | 이거는 각각의 샘플들이 서로 correlation이 있는지, 3번 가정에 대해서 체크한 것. 근데 애초에 Test Statistics만 있고, P-value도 없어서 별로 쓸모가 없음. |



